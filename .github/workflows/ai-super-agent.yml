name: AI Super Agent

on:
  issue_comment:
    types: [created]

jobs:
  ai-super-agent:
    runs-on: ubuntu-latest
    if: >
      github.event.issue.title == 'AI Super Agent' || 
      github.event.issue.title == 'وكيل الذكاء الكامل'
    
    env:
      HF_API_KEY: ${{ secrets.HF_API_KEY }}
      GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      MAX_FILE_SIZE: 50000
      MAX_FILES: 20

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          pip install "open-interpreter[all]" huggingface-hub requests
          npm install -g @mermaid-js/mermaid-cli

      - name: Validate secrets
        run: |
          if [ -z "$HF_API_KEY" ]; then
            echo "Error: HF_API_KEY is not set"
            exit 1
          fi

      - name: Extract user prompt
        id: prompt
        run: |
          COMMENT="${{ github.event.comment.body }}"
          echo "prompt<<EOF" >> "$GITHUB_OUTPUT"
          echo "$COMMENT" >> "$GITHUB_OUTPUT"
          echo "EOF" >> "$GITHUB_OUTPUT"

      - name: Discover available HuggingFace models
        id: models
        run: |
          cat << 'EOP' > get_models.py
import requests, os, json
headers = {"Authorization": f"Bearer {os.environ['HF_API_KEY']}"}
response = requests.get("https://huggingface.co/api/authorized ", headers=headers)
my_user = response.json().get("user", {}).get("name", "")
list_resp = requests.get("https://huggingface.co/api/models?full=true ", headers=headers)
models = []
for m in list_resp.json():
    if (
      (m.get("private") or my_user in m.get("id", "")) and
      m.get("pipeline_tag") in (
        "text-generation", "text2text-generation", 
        "conversational", "chat", "code", "text"
      )
    ):
        models.append(m["id"])
if not models:
    models = [
        "meta-llama/Meta-Llama-3-70B-Instruct",
        "Qwen/Qwen1.5-72B-Chat",
        "deepseek-ai/deepseek-coder-33b-instruct",
        "google/gemma-7b-it",
        "microsoft/Phi-3-mini-4k-instruct"
    ]
with open("models.txt", "w") as f:
    [f.write(m + "\n") for m in models[:8]]
EOP
          python3 get_models.py

      - name: Analyze project structure
        id: readproject
        run: |
          find . -type f ! -path "./.git/*" ! -path "./.github/*" \
            -name "*.py" -o -name "*.js" -o -name "*.ts" -o -name "*.json" \
            -o -name "*.md" -o -name "*.html" -o -name "*.css" | sort > project_files.txt
          tree -a -I '.git|.github' > project_tree.txt

      - name: Generate AI prompt with context
        id: aiprompt
        run: |
          PROMPT="${{ steps.prompt.outputs.prompt }}"
          TREE="$(cat project_tree.txt)"
          
          FILE_COUNT=0
          CURRENT_SIZE=0
          
          > all_project_files.txt
          while IFS= read -r FILE; do
            if [ $FILE_COUNT -ge ${{ env.MAX_FILES }} ]; then break; fi
            if [ -f "$FILE" ]; then
              FILE_SIZE=$(wc -c <"$FILE")
              if [ $((CURRENT_SIZE + FILE_SIZE)) -le ${{ env.MAX_FILE_SIZE }} ]; then
                echo "===== $FILE =====" >> all_project_files.txt
                cat "$FILE" >> all_project_files.txt
                echo "" >> all_project_files.txt
                FILE_COUNT=$((FILE_COUNT + 1))
                CURRENT_SIZE=$((CURRENT_SIZE + FILE_SIZE))
              fi
            fi
          done < project_files.txt
          
          ALLFILES="$(cat all_project_files.txt)"
          
          AI_PROMPT="You are a smart agent working on a complete software project. Project structure:\n$TREE\n\nProject files (limited to ${{ env.MAX_FILES }} files and $((MAX_FILE_SIZE/1000))KB total):\n$ALLFILES\n\nUser request:\n$PROMPT\n\nNote: You can delete, modify, or recreate any file or create new files/projects entirely. Each change should be made in a separate commit for easy rollback. If the user requests to restore something you previously deleted, retrieve the latest version from git. For each action you perform, write a very brief explanation of what was done."

          echo "$AI_PROMPT" > ai_super_prompt.txt

      - name: Run AI models
        id: runmodels
        run: |
          > ai_super_responses.md
          while IFS= read -r MODEL; do
              {
                echo ""
                echo "## [$MODEL]"
                interpreter --model "$MODEL" --hf --hf-token "$HF_API_KEY" \
                  --no-stream --no-tty --text "$(cat ai_super_prompt.txt)" || \
                  echo "Failed with model $MODEL"
              } >> ai_super_responses.md
          done < models.txt

      - name: Apply AI suggested changes
        id: applychanges
        run: |
          grep -E '^(git |echo |rm |mv |cp |mkdir |cat |touch )' \
            ai_super_responses.md > ai_commands.sh || true
          
          if [ -s ai_commands.sh ]; then
            echo "Applying changes:"
            cat ai_commands.sh
            
            sed -i 's/^rm /rm -f /' ai_commands.sh
            sed -i 's/^mv /mv -f /' ai_commands.sh
            sed -i 's/^cp /cp -f /' ai_commands.sh
            
            bash ai_commands.sh || echo "Some commands failed"
          else
            echo "No changes proposed"
          fi

      - name: Commit and push changes
        id: commit
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          
          if [ -n "$(git status --porcelain)" ]; then
            git add . || echo "Failed to add files"
            git commit -am "AI Super Agent: Implementing user request" || echo "Commit failed"
            
            git push || echo "Push failed"
          else
            echo "No changes to commit"
          fi

      - name: Respond to issue
        id: reply
        run: |
          REPLY="$(cat ai_super_responses.md)"
          gh issue comment "${{ github.event.issue.number }}" --body "$REPLY"

      - name: Cleanup temporary files
        if: always()
        run: |
          rm -f ai_super_prompt.txt ai_super_responses.md ai_commands.sh 
          rm -f models.txt project_files.txt project_tree.txt all_project_files.txt get_models.py
